{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2f6be364",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row_n           0\n",
      "id              1\n",
      "name            0\n",
      "gender          0\n",
      "species         0\n",
      "birthday        0\n",
      "personality     0\n",
      "song           11\n",
      "phrase          0\n",
      "full_id         0\n",
      "url             0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Import dataset\n",
    "url = \"https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-05-05/villagers.csv\"\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "# Check for missing values\n",
    "missing_values = df.isna().sum()\n",
    "\n",
    "# Print missing values count\n",
    "print(missing_values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "14c8f537",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(391, 11)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset from the provided URL\n",
    "url = 'https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-05-05/villagers.csv'\n",
    "villagers_data = pd.read_csv(url)\n",
    "\n",
    "# Print the number of rows and columns\n",
    "print(villagers_data.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8bed789",
   "metadata": {},
   "source": [
    "2.2 'observation' is rows in the dataset, in the dataset i used means each villager. 'variables' is more specific than the observation it is\n",
    "it present each specific features in the observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "36a85292",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            row_n\n",
      "count  391.000000\n",
      "mean   239.902813\n",
      "std    140.702672\n",
      "min      2.000000\n",
      "25%    117.500000\n",
      "50%    240.000000\n",
      "75%    363.500000\n",
      "max    483.000000\n",
      "species\n",
      "cat          23\n",
      "rabbit       20\n",
      "frog         18\n",
      "squirrel     18\n",
      "duck         17\n",
      "dog          16\n",
      "cub          16\n",
      "pig          15\n",
      "bear         15\n",
      "mouse        15\n",
      "horse        15\n",
      "bird         13\n",
      "penguin      13\n",
      "sheep        13\n",
      "elephant     11\n",
      "wolf         11\n",
      "ostrich      10\n",
      "deer         10\n",
      "eagle         9\n",
      "gorilla       9\n",
      "chicken       9\n",
      "koala         9\n",
      "goat          8\n",
      "hamster       8\n",
      "kangaroo      8\n",
      "monkey        8\n",
      "anteater      7\n",
      "hippo         7\n",
      "tiger         7\n",
      "alligator     7\n",
      "lion          7\n",
      "bull          6\n",
      "rhino         6\n",
      "cow           4\n",
      "octopus       3\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "url = 'https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-05-05/villagers.csv'\n",
    "villagers_data = pd.read_csv(url)\n",
    "\n",
    "# Get a summary of numeric columns\n",
    "print(villagers_data.describe())\n",
    "\n",
    "# Count unique values in a categorical column (e.g., species)\n",
    "print(villagers_data['species'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "89118288",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the dataset: (891, 15)\n",
      "\n",
      "Summary of numeric columns:\n",
      "         survived      pclass         age       sibsp       parch        fare\n",
      "count  891.000000  891.000000  714.000000  891.000000  891.000000  891.000000\n",
      "mean     0.383838    2.308642   29.699118    0.523008    0.381594   32.204208\n",
      "std      0.486592    0.836071   14.526497    1.102743    0.806057   49.693429\n",
      "min      0.000000    1.000000    0.420000    0.000000    0.000000    0.000000\n",
      "25%      0.000000    2.000000   20.125000    0.000000    0.000000    7.910400\n",
      "50%      0.000000    3.000000   28.000000    0.000000    0.000000   14.454200\n",
      "75%      1.000000    3.000000   38.000000    1.000000    0.000000   31.000000\n",
      "max      1.000000    3.000000   80.000000    8.000000    6.000000  512.329200\n",
      "\n",
      "Non-numeric columns:\n",
      "Index(['sex', 'embarked', 'class', 'who', 'deck', 'embark_town', 'alive'], dtype='object')\n",
      "\n",
      "Missing values in numeric columns:\n",
      "survived         0\n",
      "pclass           0\n",
      "sex              0\n",
      "age            177\n",
      "sibsp            0\n",
      "parch            0\n",
      "fare             0\n",
      "embarked         2\n",
      "class            0\n",
      "who              0\n",
      "adult_male       0\n",
      "deck           688\n",
      "embark_town      2\n",
      "alive            0\n",
      "alone            0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the Titanic dataset\n",
    "url = 'https://raw.githubusercontent.com/mwaskom/seaborn-data/master/titanic.csv'\n",
    "titanic_data = pd.read_csv(url)\n",
    "\n",
    "# Get the shape of the dataset\n",
    "print(\"Shape of the dataset:\", titanic_data.shape)\n",
    "\n",
    "# Summary of numeric columns\n",
    "print(\"\\nSummary of numeric columns:\")\n",
    "print(titanic_data.describe())\n",
    "\n",
    "# Check for non-numeric columns\n",
    "print(\"\\nNon-numeric columns:\")\n",
    "print(titanic_data.select_dtypes(include='object').columns)\n",
    "\n",
    "# Check for missing values in numeric columns\n",
    "print(\"\\nMissing values in numeric columns:\")\n",
    "print(titanic_data.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45716d97",
   "metadata": {},
   "source": [
    "\"attribute\" give you back information directly from the row dataset, it don't need to compute, \"method\" do some calculations and give you back the result. for example, titanic_data.shape return the row and columns of the dataset, and titanic_data.describe() return the summary data of the data sat."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5b55704",
   "metadata": {},
   "source": [
    "6.\n",
    "Count:\n",
    "\n",
    "Definition: The number of non-missing values in the column. It tells you how many valid entries are present in that column.\n",
    "Mean:\n",
    "\n",
    "Definition: The average value of the data in the column. It's calculated by summing all the values and then dividing by the count of non-missing values.\n",
    "Std (Standard Deviation):\n",
    "\n",
    "Definition: A measure of the amount of variation or dispersion in the columnâ€™s values. A low standard deviation means that values tend to be close to the mean, while a high standard deviation indicates that values are spread out over a wider range.\n",
    "Min:\n",
    "\n",
    "Definition: The smallest value in the column.\n",
    "25% (25th Percentile or First Quartile):\n",
    "\n",
    "Definition: The value below which 25% of the data falls. It divides the lowest 25% of the data from the remaining 75%.\n",
    "50% (50th Percentile or Median):\n",
    "\n",
    "Definition: The middle value of the data. Half of the data falls below this value, and half is above it.\n",
    "75% (75th Percentile or Third Quartile):\n",
    "\n",
    "Definition: The value below which 75% of the data falls. It divides the lowest 75% of the data from the remaining 25%.\n",
    "Max:\n",
    "\n",
    "Definition: The largest value in the column."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22106665",
   "metadata": {},
   "source": [
    "7-1\n",
    "if you want to remove rows that contain missing values, df.dropna() might be peferred over using del df['col']\n",
    "for example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4b714c7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values before using df.dropna():\n",
      "survived         0\n",
      "pclass           0\n",
      "sex              0\n",
      "age            177\n",
      "sibsp            0\n",
      "parch            0\n",
      "fare             0\n",
      "embarked         2\n",
      "class            0\n",
      "who              0\n",
      "adult_male       0\n",
      "deck           688\n",
      "embark_town      2\n",
      "alive            0\n",
      "alone            0\n",
      "dtype: int64\n",
      "\n",
      "Missing values after using df.dropna():\n",
      "survived       0\n",
      "pclass         0\n",
      "sex            0\n",
      "age            0\n",
      "sibsp          0\n",
      "parch          0\n",
      "fare           0\n",
      "embarked       0\n",
      "class          0\n",
      "who            0\n",
      "adult_male     0\n",
      "deck           0\n",
      "embark_town    0\n",
      "alive          0\n",
      "alone          0\n",
      "dtype: int64\n",
      "\n",
      "Shape before cleaning: (891, 15)\n",
      "Shape after cleaning: (182, 15)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the Titanic dataset\n",
    "url = 'https://raw.githubusercontent.com/mwaskom/seaborn-data/master/titanic.csv'\n",
    "titanic_data = pd.read_csv(url)\n",
    "\n",
    "# Step 1: Check missing values before cleaning\n",
    "print(\"Missing values before using df.dropna():\")\n",
    "print(titanic_data.isnull().sum())\n",
    "\n",
    "# Step 2: Drop rows with missing values\n",
    "cleaned_data = titanic_data.dropna()\n",
    "\n",
    "# Step 3: Check missing values after using df.dropna()\n",
    "print(\"\\nMissing values after using df.dropna():\")\n",
    "print(cleaned_data.isnull().sum())\n",
    "\n",
    "# Step 4: Check the shape before and after cleaning\n",
    "print(\"\\nShape before cleaning:\", titanic_data.shape)\n",
    "print(\"Shape after cleaning:\", cleaned_data.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6b7add9",
   "metadata": {},
   "source": [
    "7-2\n",
    "If there is a column with a lot of data missed, you can use del df['col'] might be preferred over using df.dropna(), for example, in the same data site there is a column \"cabin\" it has a lot of missing values, and don't have much analysis value, its better to remove the whole column instead of removing the rows which might cause loss of data. \n",
    "for example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "78383a9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   survived  pclass     sex   age  sibsp  parch     fare embarked  class  \\\n",
      "0         0       3    male  22.0      1      0   7.2500        S  Third   \n",
      "1         1       1  female  38.0      1      0  71.2833        C  First   \n",
      "2         1       3  female  26.0      0      0   7.9250        S  Third   \n",
      "3         1       1  female  35.0      1      0  53.1000        S  First   \n",
      "4         0       3    male  35.0      0      0   8.0500        S  Third   \n",
      "\n",
      "     who  adult_male deck  embark_town alive  alone  \n",
      "0    man        True  NaN  Southampton    no  False  \n",
      "1  woman       False    C    Cherbourg   yes  False  \n",
      "2  woman       False  NaN  Southampton   yes   True  \n",
      "3  woman       False    C  Southampton   yes  False  \n",
      "4    man        True  NaN  Southampton    no   True  \n",
      "survived         0\n",
      "pclass           0\n",
      "sex              0\n",
      "age            177\n",
      "sibsp            0\n",
      "parch            0\n",
      "fare             0\n",
      "embarked         2\n",
      "class            0\n",
      "who              0\n",
      "adult_male       0\n",
      "deck           688\n",
      "embark_town      2\n",
      "alive            0\n",
      "alone            0\n",
      "dtype: int64\n",
      "Index(['survived', 'pclass', 'sex', 'age', 'sibsp', 'parch', 'fare',\n",
      "       'embarked', 'class', 'who', 'adult_male', 'embark_town', 'alive',\n",
      "       'alone'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the Titanic dataset\n",
    "url = 'https://raw.githubusercontent.com/mwaskom/seaborn-data/master/titanic.csv'\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "# Show the first few rows to see the columns and missing values\n",
    "print(df.head())\n",
    "\n",
    "# Check how many missing values there are in each column\n",
    "print(df.isna().sum())\n",
    "\n",
    "# Use del to completely remove the 'deck' column since it has many missing values and might not be relevant\n",
    "del df['deck']\n",
    "\n",
    "# Print the DataFrame columns after deletion\n",
    "print(df.columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06bda168",
   "metadata": {},
   "source": [
    "7-3\n",
    "this can prevent necessary row got deleted by df.dropna() because if there are only 1 missing value in that row, df.dropna() will delete the whole row, by doing del df['col'] can delete the unnecessary column where it has the most missed data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4838e666",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial shape: (891, 15)\n",
      "survived         0\n",
      "pclass           0\n",
      "sex              0\n",
      "age            177\n",
      "sibsp            0\n",
      "parch            0\n",
      "fare             0\n",
      "embarked         2\n",
      "class            0\n",
      "who              0\n",
      "adult_male       0\n",
      "deck           688\n",
      "embark_town      2\n",
      "alive            0\n",
      "alone            0\n",
      "dtype: int64\n",
      "Shape after cleaning: (712, 14)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the Titanic dataset\n",
    "url = 'https://raw.githubusercontent.com/mwaskom/seaborn-data/master/titanic.csv'\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "# Display initial row and column count\n",
    "print(\"Initial shape:\", df.shape)\n",
    "\n",
    "# Check how many missing values there are in each column\n",
    "print(df.isna().sum())\n",
    "\n",
    "# Delete 'deck' column before dropping rows with missing values\n",
    "del df['deck']\n",
    "\n",
    "# Now, drop rows with any missing values\n",
    "df_cleaned = df.dropna()\n",
    "\n",
    "# Display row and column count after cleaning\n",
    "print(\"Shape after cleaning:\", df_cleaned.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b900dc99",
   "metadata": {},
   "source": [
    "7-4\n",
    "approach:\n",
    "1.check which column has the most missing values, if it have too many missing value it might not be useful, so delete it using del df['']\n",
    "2.clean remaining missing data, use df.dropna() clean the rows with missing values.\n",
    "\n",
    "before:\n",
    "Shape: (891 rows, 15 columns)\n",
    "Missing values per column:\n",
    "deck: 688 missing values\n",
    "age: 177 missing values\n",
    "embarked: 2 missing values\n",
    "embark_town: 2 missing value\n",
    "after:\n",
    "Final shape: (712 rows, 14 columns)\n",
    "Missing values per column: No missing values, as all missing data has been removed.\n",
    "\n",
    "Justification for Approach:\n",
    "i choose to use del df['col'] before df.dropna() because the column \"deck\" have 688 missing value, if i choose to use df.dropna() before deleting the\"deck\" column will cause 77% of rows removed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "45d33125",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial shape: (891, 15)\n",
      "Missing values before cleaning:\n",
      "survived         0\n",
      "pclass           0\n",
      "sex              0\n",
      "age            177\n",
      "sibsp            0\n",
      "parch            0\n",
      "fare             0\n",
      "embarked         2\n",
      "class            0\n",
      "who              0\n",
      "adult_male       0\n",
      "deck           688\n",
      "embark_town      2\n",
      "alive            0\n",
      "alone            0\n",
      "dtype: int64\n",
      "\n",
      "Final shape after cleaning: (712, 14)\n",
      "Missing values after cleaning:\n",
      "survived       0\n",
      "pclass         0\n",
      "sex            0\n",
      "age            0\n",
      "sibsp          0\n",
      "parch          0\n",
      "fare           0\n",
      "embarked       0\n",
      "class          0\n",
      "who            0\n",
      "adult_male     0\n",
      "embark_town    0\n",
      "alive          0\n",
      "alone          0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the Titanic dataset\n",
    "url = 'https://raw.githubusercontent.com/mwaskom/seaborn-data/master/titanic.csv'\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "# Initial shape and missing values\n",
    "print(\"Initial shape:\", df.shape)\n",
    "print(\"Missing values before cleaning:\")\n",
    "print(df.isna().sum())\n",
    "\n",
    "# Step 1: Remove the 'deck' column since it has too many missing values (more than 75%)\n",
    "del df['deck']\n",
    "\n",
    "# Step 2: Drop rows with missing values in remaining important columns\n",
    "df_cleaned = df.dropna()\n",
    "\n",
    "# Final shape and missing values\n",
    "print(\"\\nFinal shape after cleaning:\", df_cleaned.shape)\n",
    "print(\"Missing values after cleaning:\")\n",
    "print(df_cleaned.isna().sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54465b94",
   "metadata": {},
   "source": [
    "8-1\n",
    "df.groupby(\"col1\"), this groups every unique value in one group and form a seprate column,\n",
    "[\"col2\"], this select the choosen column and form a table with col1, for example, (\"income\") shows the income of the person in a dataset, [\"age\"] is the column of person's age in the data set, and the table will be about the stat of people's income when they at specific age.\n",
    ".describe() will show the summary of stats in a table about col2 and col1, if the col2 is numerical it out puts details: count, mean, std, min, 25%, 50%, 75%, max. if the col2 is non numerical it will show the count, unique top and freq.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "91f9a0d3",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'age' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 12\u001b[0m\n\u001b[1;32m      9\u001b[0m url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     10\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(url, header\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, names\u001b[38;5;241m=\u001b[39mcolumn_names, na_values\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m ?\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 12\u001b[0m grouped_description \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mgroupby(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mincome\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[43mage\u001b[49m]\u001b[38;5;241m.\u001b[39mdescribe()\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(grouped_description)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'age' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "column_names = [\n",
    "    'age', 'workclass', 'fnlwgt', 'education', 'education_num', 'marital_status',\n",
    "    'occupation', 'relationship', 'race', 'sex', 'capital_gain', 'capital_loss',\n",
    "    'hours_per_week', 'native_country', 'income'\n",
    "]\n",
    "\n",
    "url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data'\n",
    "df = pd.read_csv(url, header=None, names=column_names, na_values=' ?')\n",
    "\n",
    "grouped_description = df.groupby(\"income\")[\"age\"].describe()\n",
    "print(grouped_description)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96cb4aa0",
   "metadata": {},
   "source": [
    "8-2\n",
    "It's fundamentally different because in \"df.describe\" count show the non missing values in each columns, treating columns independently. In\n",
    "df.groupby(\"col1\")[\"col2\"].describe(), it shows how many values in col2 exist for each unique group in col1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9d49a67",
   "metadata": {},
   "source": [
    "8-3\n",
    "errors:\n",
    "A) NameError: name 'pd' is not defined\n",
    "B)FileNotFoundError: [Errno 2] No such file or directory: 'titanic.csv'\n",
    "C)NameError: name 'DF' is not defined\n",
    "D)SyntaxError: '(' was never closed\n",
    "E)AttributeError: 'DataFrame' object has no attribute 'group_by' OR AttributeError: 'DataFrame' object has no attribute 'describle'\n",
    "F)KeyError: 'Sex'or KeyError: 'Age'\n",
    "G)NameError: name 'income' is not defined OR NameError: name 'age' is not defined\n",
    "I don't think google search is a faster way than chatgpt in terms of fixing errors, by typing the error to chatbot, it can directly tell you where is wrong with the code, but in google search you need to find the corresponding one among a lot of site"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "04776605",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 8\u001b[0m\n\u001b[1;32m      1\u001b[0m column_names \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mage\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mworkclass\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfnlwgt\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124meducation\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124meducation_num\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmarital_status\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124moccupation\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelationship\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrace\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msex\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcapital_gain\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcapital_loss\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhours_per_week\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnative_country\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mincome\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      5\u001b[0m ]\n\u001b[1;32m      7\u001b[0m url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m----> 8\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241m.\u001b[39mread_csv(url, header\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, names\u001b[38;5;241m=\u001b[39mcolumn_names, na_values\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m ?\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     10\u001b[0m grouped_description \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mgroupby(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mincome\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mage\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mdescribe()\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(grouped_description)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1d01bfac",
   "metadata": {},
   "source": [
    "summary:\n",
    "df = pd.read_csv(url) Loads the dataset from a URL into a pandas DataFrame.\n",
    "df.shape: Returns the dimensions (rows, columns) of the DataFrame.\n",
    "df.describe(): Provides summary statistics (count, mean, std, etc.) for numerical columns.\n",
    "df['column'].value_counts(): Returns the count of unique values in the specified column.\n",
    "df.dropna(): Removes rows with any missing values (NaN) from the DataFrame.\n",
    "del df['col']: Deletes the specified column from the DataFrame.\n",
    "df.groupby(\"col1\")[\"col2\"].describe(): Groups the data by values in col1 and returns descriptive statistics for col2 within each group.\n",
    "\n",
    "chatlog:\n",
    "https://chatgpt.com/share/66e39a2b-8284-8003-a0b9-028c1027ffd1\n",
    "https://chatgpt.com/share/66e39a41-e860-8003-baf2-40205095cb9d\n",
    "https://chatgpt.com/share/66e39a4e-bcbc-8003-a57f-8347cdceaaa6\n",
    "https://chatgpt.com/share/66e39a5c-0f20-8003-bec6-9732b6aaa220\n",
    "https://chatgpt.com/share/66e39a66-76f8-8003-9146-8d6c36d44cf0\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
