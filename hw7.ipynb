{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8c966e17",
   "metadata": {},
   "source": [
    "1.\n",
    "Simple Linear Regression (SLR) models the relationship between a single continuous predictor and an outcome with the equation:\n",
    "\n",
    "Outcome = β₀ + β₁ * Predictor\n",
    "\n",
    "In contrast, Multiple Linear Regression (MLR) extends SLR by incorporating multiple predictors, including both continuous and indicator (binary) variables, such as:\n",
    "\n",
    "Outcome = β₀ + β₁ * Predictor₁ + β₂ * Indicator\n",
    "\n",
    "This allows MLR to control for several factors simultaneously, enhancing accuracy and providing a more comprehensive analysis. When an indicator variable is added alongside a continuous variable, the model adjusts the baseline (β₀) and accounts for category-specific effects (β₂). Introducing an interaction term, like:\n",
    "\n",
    "Outcome = β₀ + β₁ * Predictor + β₂ * Indicator + β₃ * Predictor * Indicator\n",
    "\n",
    "enables the effect of the continuous predictor to vary by category. Additionally, for a non-binary categorical variable with k categories, MLR uses k-1 indicator variables (e.g., Outcome = β₀ + β₁ * Indicator₁ + β₂ * Indicator₂ + ... + βₖ₋₁ * Indicatorₖ₋₁) to represent the categories relative to a baseline group. This approach avoids multicollinearity and allows comparisons across groups. Overall, MLR provides greater flexibility and deeper insights compared to SLR by effectively handling multiple and categorical predictors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f85085d9",
   "metadata": {},
   "source": [
    "2.\n",
    "Without Interaction (Continuous Variables): Sales = β₀ + β₁ * TV_Spend + β₂ * Online_Spend\n",
    "\n",
    "Assumes each advertising type independently affects sales.\n",
    "With Interaction (Continuous Variables): Sales = β₀ + β₁ * TV_Spend + β₂ * Online_Spend + β₃ * TV_Spend * Online_Spend\n",
    "\n",
    "Allows the effect of one ad type to change based on the amount spent on the other.\n",
    "Using these models, predictions without interaction assume the combined effect is just the sum of each ad type's effect. With interaction, the combined effect can be greater or lesser, showing how the ads work together.\n",
    "\n",
    "If advertising budgets are categorized as \"high\" or \"low\" (binary):\n",
    "\n",
    "Without Interaction (Binary Variables): Sales = β₀ + β₁ * High_TV + β₂ * High_Online\n",
    "\n",
    "Compares each high category to the baseline (low TV and low online).\n",
    "With Interaction (Binary Variables): Sales = β₀ + β₁ * High_TV + β₂ * High_Online + β₃ * High_TV * High_Online\n",
    "\n",
    "Captures the additional effect when both TV and online advertising are high."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6329bc57",
   "metadata": {},
   "source": [
    "3."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60544ba4",
   "metadata": {},
   "source": [
    "4.\n",
    "The apparent contradiction between a low R-squared (17.6%) and large, significant coefficients arises because R-squared and p-values assess different aspects of the model. R-squared measures the overall proportion of variability in the outcome (HP) that the model explains. A low R-squared indicates that, collectively, the predictors (like Sp. Def and Generation) account for only a small portion of the variation in HP.\n",
    "\n",
    "On the other hand, p-values evaluate the significance of each individual coefficient, indicating whether each predictor has a statistically meaningful relationship with the outcome. Large coefficients with strong p-values mean that each predictor reliably affects HP when considered alone or alongside others, but these individual effects might not add up to explain much of the total variability in the data.\n",
    "\n",
    "In summary, while the predictors significantly influence HP individually (as shown by the significant coefficients), they do not collectively capture much of the overall variation in HP, leading to a low R-squared. This highlights that significant predictors do not necessarily result in a model with high explanatory power."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88c6e72d",
   "metadata": {},
   "source": [
    "5."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e54baf0",
   "metadata": {},
   "source": [
    "6."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "962bd043",
   "metadata": {},
   "source": [
    "7.\n",
    "Model5 extends Model3 and Model4 by incorporating significant predictors to improve the model's explanatory power. The equation for Model5 is:\n",
    "\n",
    "HP = β₀ + β₁·Attack + β₂·Defense + β₃·Speed + β₄·Legendary + β₅·Sp.Def + β₆·Sp.Atk + β₇·(Generation) + β₈·(Type 1) + β₉·(Type 2)\n",
    "\n",
    "Model6 refines Model5 by selecting only the most impactful predictors and reducing complexity to address potential multicollinearity. The equation for Model6 is:\n",
    "\n",
    "HP = β₀ + β₁·Attack + β₂·Speed + β₃·Sp.Def + β₄·Sp.Atk + β₅·Indicator(Type 1 = \"Normal\") + β₆·Indicator(Type 1 = \"Water\") + β₇·Indicator(Generation = 2) + β₈·Indicator(Generation = 5)\n",
    "\n",
    "Model7 builds on Model6 by adding interaction terms among continuous variables to capture synergistic effects and applies centering and scaling to mitigate multicollinearity. The equation for Model7 is:\n",
    "\n",
    "HP = β₀ + (β₁·Attack × β₂·Speed × β₃·Sp.Def × β₄·Sp.Atk) + β₅·Indicator(Type 1 = \"Normal\") + β₆·Indicator(Type 1 = \"Water\") + β₇·Indicator(Generation = 2) + β₈·Indicator(Generation = 5)\n",
    "\n",
    "In summary, each model progressively enhances predictive accuracy by adding significant variables, refining selections, and incorporating interactions, while addressing multicollinearity through centering and scaling in the final model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86a85495",
   "metadata": {},
   "source": [
    "8."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3ade00e",
   "metadata": {},
   "source": [
    "9.\n",
    "The illustration highlights the trade-off between model complexity and reliability in regression analysis. Model7_fit is more complex than Model6_fit, incorporating additional interaction terms and scaled variables. While Model7_fit shows improved \"out of sample\" R-squared, indicating better predictive performance on new data, it also has many coefficients with weaker statistical significance. This complexity increases the risk of overfitting, where the model captures noise specific to the training data rather than general patterns. In contrast, Model6_fit is simpler, with stronger and more consistent coefficient significance, enhancing its interpretability and generalizability. Despite Model7_fit performing better in some metrics, Model6_fit is often preferred because it strikes a better balance between predictive accuracy and the ability to reliably interpret the effects of predictors without being overly tailored to the training data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
